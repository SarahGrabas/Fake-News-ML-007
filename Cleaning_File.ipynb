{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This file: \n",
    "- Cleans the content for every article.\n",
    "- Uses stemming on the cleaned content.\n",
    "- Wordcount before and after cleaning.\n",
    "- Creates a plot displaying the 10.000 most common words used in articles.\n",
    "- Gives every type a broad type, so all articles are marked as either Fake or Reliable news.\n",
    "- Cleans the BBC data set\n",
    "- Cleans the liar data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing modules\n",
    "import re\n",
    "import pandas as pd \n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from cleantext import clean \n",
    "from collections import Counter \n",
    "from pandarallel import pandarallel\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chose the file you want to clean\n",
    "\n",
    "If liar or bbc, scroll down until valid title. Remember to run the all_lower, clean and stem function so they can be called for the cleaning :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose the wanted filename\n",
    "\n",
    "filename = \"full_train_set.csv\"\n",
    "# filename = \"full_val_set.csv\"\n",
    "# filename = \"full_test_set.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = df[[\"content\",\"id\"]].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wordcount before cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncleaned vocalbulary: 4970256\n"
     ]
    }
   ],
   "source": [
    "# #Raw dataframe 'content' is converted to a string.\n",
    "# uncleaned_string = '\\n'.join(df[\"content\"].astype(str))\n",
    "\n",
    "# #'uncleaned_string' is converted to a list.\n",
    "# uncleaned_list=uncleaned_string.split() \n",
    "\n",
    "# #Converting 'uncleaned_string' to a set, so repeated element only appear once.\n",
    "# uncleaned_set=set(uncleaned_list)\n",
    "\n",
    "# #Lenght of 'uncleaned_set' is the wordcount before cleaning.\n",
    "# print(\"Uncleaned vocalbulary:\",len(uncleaned_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4970256\n",
    "This is the total amounts of words in the uncleaned vocalbulary in the training set. \n",
    "\n",
    "The reason we have marked the above code as a comment, is because it completely eats ups ones RAM, and therefore we do not recommend running the code. We have run it when necessary and restarted the kernel, since it takes too much processessing power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions used in the cleaning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function making text lower case\n",
    "def all_lower(x):\n",
    "    x= x.lower()\n",
    "    return x\n",
    "\n",
    "#Function removing special characters\n",
    "def remove_special_chars(x):\n",
    "    import re \n",
    "    return re.sub(r\"[^a-zA-Z0-9<>]\", \" \", x)\n",
    "\n",
    "\n",
    "#Function replacing dates with <DATE>\n",
    "def sub_dates(x):\n",
    "    import re \n",
    "    sub_dates = re.sub(r'\\d{4}[-/]\\d{2}[-/]\\d{2}|\\d{2}[-/]\\d{2}[-/]\\d{4}', ' <DATE> ', x)\n",
    "    sub_dates = re.sub(r'\\b[a-z]+\\s\\d{1,2},\\s\\d{4}\\b', '<DATE>', sub_dates)\n",
    "    sub_dates = re.sub(r'\\b\\d{1,2}[,]?\\s[a-zA-Z]+\\s\\d{4}\\b', '<DATE>', sub_dates)\n",
    "    return sub_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "\n",
      "WARNING: You are on Windows. If you detect any issue with pandarallel, be sure you checked out the Troubleshooting page:\n",
      "https://nalepae.github.io/pandarallel/troubleshooting/\n"
     ]
    }
   ],
   "source": [
    "#Initializing pandarallel\n",
    "pandarallel.initialize(progress_bar=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main cleaning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df):\n",
    "    from cleantext import clean \n",
    "    from nltk.tokenize import word_tokenize\n",
    "    from nltk.corpus import stopwords\n",
    "\n",
    "    #Stopwords from the module nltk\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    #Replacing NaN values with empty string.\n",
    "    df['content']=df['content'].astype(str).fillna(\"\")\n",
    "    \n",
    "\n",
    "    #Applying the 'all_lower' function on the 'content' column \n",
    "    df['content']=df['content'].parallel_apply(all_lower)\n",
    "\n",
    "    #Applying the 'sub_dates' function on the 'content' column \n",
    "    df['content']=df['content'].parallel_apply(sub_dates)          \n",
    "    \n",
    "    #Applying the clean function from the 'cleantext' module on the 'content' column \n",
    "    df['content']=df['content'].parallel_apply(                   \n",
    "        lambda df: clean(str(df), lower=True, no_urls=True, no_emails=True, no_numbers=True, no_punct=True, no_currency_symbols=True))\n",
    "    \n",
    "    #Applying word_tokenize function from nltk module, that makes 'content' to a list of strings.\n",
    "    df['content']=df['content'].parallel_apply(lambda x: word_tokenize(str(x)))  \n",
    "    \n",
    "    #Removing the 'exclude_words' from 'content'\n",
    "    exclude_words = {\"number\", \"date\", \"url\", \"email\", \"<\", \">\"}\n",
    "    \n",
    "    df['content'] = df['content'].parallel_apply(\n",
    "    lambda x: [word for word in x if word not in exclude_words])\n",
    "    \n",
    "    #Removing the 'stop_words' from 'content'\n",
    "    df['content']=df['content'].parallel_apply(\n",
    "        lambda x: [word for word in x if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae9d8d823bd24834942535424a9b0fea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=90368), Label(value='0 / 90368')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "537c785f07d14ca68964e5d4beea8aa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=90368), Label(value='0 / 90368')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "775fddc2b5e24b57a937d75e0b96b0dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=90368), Label(value='0 / 90368')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "045bf343db7d430382ae0357eb614118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=90368), Label(value='0 / 90368')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8afd40c913804c2d8ab679cbfa814fb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=90368), Label(value='0 / 90368')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b844c560df7441f9ea25aadbe4de0fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=90368), Label(value='0 / 90368')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Call the clean function on the copy df\n",
    "clean_df(temp_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduction rate of vocabulary after cleaning and WITHOUT stemming.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned vocabulary 1908946\n",
      "Percentage change: 61.59260207120116 %\n"
     ]
    }
   ],
   "source": [
    "# #Dataframe 'content' is converted to a string. 'content' is now cleaned. \n",
    "# cleaned_string = '\\n'.join(temp_df[\"content\"].astype(str))\n",
    "\n",
    "# #'cleaned_string' is converted to a list\n",
    "# cleaned_list=cleaned_string.split() \n",
    "\n",
    "# #'cleaned_list' is converted to a set, so any repeated element only appear once.\n",
    "# cleaned_set=set(cleaned_list)\n",
    "\n",
    "# #Lenght of 'cleaned_set' is wordcount after cleaning.\n",
    "# print(\"Cleaned vocabulary\",len(cleaned_set))   \n",
    "\n",
    "# #Wordcount before cleaning:\n",
    "# prior =  4970256\n",
    " \n",
    "# #Wordcount after cleaning:\n",
    "# after = len(cleaned_set)  \n",
    "\n",
    "# #Removed words in the cleaning process  \n",
    "# diff = prior - after  \n",
    "\n",
    "\n",
    "# print(\"Percentage change:\", (diff / prior) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1908946\n",
    "This is the total amounts of words in the cleaned but NOT stemmed vocalbulary in the training set. \n",
    "Reduction Rate: 61.59260207120116 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function used for stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing PorterStemmer from nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "def stemming(df):\n",
    "    ps = PorterStemmer()\n",
    "\n",
    "    #Stemming for every word in every line the 'content' column\n",
    "    df['content'] = df['content'].parallel_apply(lambda x: \" \".join(ps.stem(word) for word in x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd58523725ab4b9eaeeae94c646c75d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=90368), Label(value='0 / 90368')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemming(temp_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapping the temporary datafram back to the orignal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using map to update 'content' based on 'id'\n",
    "df['content'] = df['id'].map(temp_df.set_index('id')['content'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduction rate of vocabulary after cleaning and stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned vocabulary 1569236\n",
      "Percentage change: 68.42746128167241 %\n"
     ]
    }
   ],
   "source": [
    "# #Dataframe 'content' is converted to a string. 'content' is now cleaned. \n",
    "# cleaned_string = '\\n'.join(temp_df[\"content\"].astype(str))\n",
    "\n",
    "# #'cleaned_string' is converted to a list\n",
    "# cleaned_list=cleaned_string.split() \n",
    "\n",
    "# #'cleaned_list' is converted to a set, so any repeated element only appear once.\n",
    "# cleaned_set=set(cleaned_list)\n",
    "\n",
    "# #Lenght of 'cleaned_set' is wordcount after cleaning.\n",
    "# print(\"Cleaned vocabulary\",len(cleaned_set))   \n",
    "\n",
    "# #Wordcount before cleaning:\n",
    "# prior = 4970256 \n",
    " \n",
    "# #Wordcount after cleaning:\n",
    "# after = len(cleaned_set)  \n",
    "\n",
    "# #Removed words in the cleaning process  \n",
    "# diff = prior - after  \n",
    "\n",
    "# print(\"Percentage change:\", (diff / prior) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1569236\n",
    "This is the total amounts of words in the cleaned AND stemmed vocalbulary in the training set. \n",
    "Reduction Rate: 68.42746128167241 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on what file that has been cleaned, choose the right name for the saved csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the final datafram to a csv.\n",
    "\n",
    "\n",
    "df.to_csv('full_train_cleaned.csv')\n",
    "# df.to_csv('full_val_cleaned.csv')\n",
    "# df.to_csv('full_test_cleaned.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the BBC articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the bbc data set\n",
    "\n",
    "bbc_filename = \"BBC_broad_content.csv\"\n",
    "df_BBC = pd.read_csv(bbc_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "914716595cd04f209c4a7c799f4c70d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=91), Label(value='0 / 91'))), HBox…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ae4c87bce3f4a0884ed59f1656f2344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=91), Label(value='0 / 91'))), HBox…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e359b2c42174bfd980d405d5e30ee90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=91), Label(value='0 / 91'))), HBox…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df2ca32a3b9b42fa9cf16cd176c69174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=91), Label(value='0 / 91'))), HBox…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4ce69fa64bb4ddf9b486de09dd1c5a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=91), Label(value='0 / 91'))), HBox…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb2f7aa04cce4e42b95f9567d950860b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=91), Label(value='0 / 91'))), HBox…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clean_df(df_BBC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d21e4c4b61e64f2c95ee44322a37deab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=91), Label(value='0 / 91'))), HBox…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemming(df_BBC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the final dataframe to a csv.\n",
    "df_BBC.to_csv('bbc_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the liar data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the  data set\n",
    "df_liar = pd.read_csv(\"liar_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Statement</th>\n",
       "      <th>subject(s)</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Speaker job title</th>\n",
       "      <th>State info</th>\n",
       "      <th>party affiliation</th>\n",
       "      <th>barely true counts</th>\n",
       "      <th>false counts</th>\n",
       "      <th>half true counts</th>\n",
       "      <th>mostly true counts</th>\n",
       "      <th>pants on fire counts</th>\n",
       "      <th>context (venue/location)</th>\n",
       "      <th>broad_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2635.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>dwayne-bohac</td>\n",
       "      <td>State representative</td>\n",
       "      <td>Texas</td>\n",
       "      <td>republican</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>a mailer</td>\n",
       "      <td>Fake News</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  Label                                          Statement  \\\n",
       "0  2635.json  false  Says the Annies List political group supports ...   \n",
       "\n",
       "  subject(s)       Speaker     Speaker job title State info party affiliation  \\\n",
       "0   abortion  dwayne-bohac  State representative      Texas        republican   \n",
       "\n",
       "   barely true counts  false counts  half true counts  mostly true counts  \\\n",
       "0                 0.0           1.0               0.1                 0.2   \n",
       "\n",
       "   pants on fire counts context (venue/location) broad_category  \n",
       "0                   0.3                 a mailer      Fake News  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_liar.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a new column called 'content' which contain the content of the articles.\n",
    "df_liar[\"content\"] = df_liar[\"Statement\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "\n",
      "WARNING: You are on Windows. If you detect any issue with pandarallel, be sure you checked out the Troubleshooting page:\n",
      "https://nalepae.github.io/pandarallel/troubleshooting/\n"
     ]
    }
   ],
   "source": [
    "#Initializing pandarallel\n",
    "pandarallel.initialize(progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "519c8fda655644c59960db43323d89c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=1280), Label(value='0 / 1280'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13992d660e434ad0bb6837a0452c9434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=1280), Label(value='0 / 1280'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbaa2025c3d44b9aafbf0098cf6601f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=1280), Label(value='0 / 1280'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82dfc34c301146bfae9e322fb36f0d07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=1280), Label(value='0 / 1280'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75d7289cf09f4d728d7a8b6c64a8c1fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=1280), Label(value='0 / 1280'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbdfb54691d94ab09f3640eb87d506b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=1280), Label(value='0 / 1280'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clean_df(df_liar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5181f94caf8471cb4da23bc15a18ed7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=1280), Label(value='0 / 1280'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemming(df_liar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using map to update the 'Statement' column based on ID\n",
    "df_liar['Statement'] = df_liar['ID'].map(df_liar.set_index('ID')['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deleting the 'content' column\n",
    "df_liar.drop('content', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Statement</th>\n",
       "      <th>subject(s)</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Speaker job title</th>\n",
       "      <th>State info</th>\n",
       "      <th>party affiliation</th>\n",
       "      <th>barely true counts</th>\n",
       "      <th>false counts</th>\n",
       "      <th>half true counts</th>\n",
       "      <th>mostly true counts</th>\n",
       "      <th>pants on fire counts</th>\n",
       "      <th>context (venue/location)</th>\n",
       "      <th>broad_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2635.json</td>\n",
       "      <td>false</td>\n",
       "      <td>say anni list polit group support thirdtrimest...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>dwayne-bohac</td>\n",
       "      <td>State representative</td>\n",
       "      <td>Texas</td>\n",
       "      <td>republican</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>a mailer</td>\n",
       "      <td>Fake News</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  Label                                          Statement  \\\n",
       "0  2635.json  false  say anni list polit group support thirdtrimest...   \n",
       "\n",
       "  subject(s)       Speaker     Speaker job title State info party affiliation  \\\n",
       "0   abortion  dwayne-bohac  State representative      Texas        republican   \n",
       "\n",
       "   barely true counts  false counts  half true counts  mostly true counts  \\\n",
       "0                 0.0           1.0               0.1                 0.2   \n",
       "\n",
       "   pants on fire counts context (venue/location) broad_category  \n",
       "0                   0.3                 a mailer      Fake News  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_liar.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the final liar dataframe to a csv.\n",
    "df_liar.to_csv(\"liar_cleaned.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
